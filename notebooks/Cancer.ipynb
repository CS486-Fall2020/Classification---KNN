{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This is the notebook for the breast cancer dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from KNN import KNN\n",
    "from sklearn.metrics import accuracy_score,  confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38           122.8     1001.0   \n",
       "1    842517         M        20.57         17.77           132.9     1326.0   \n",
       "2  84300903         M        19.69         21.25           130.0     1203.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33            184.6      2019.0            0.1622   \n",
       "1  ...          23.41            158.8      1956.0            0.1238   \n",
       "2  ...          25.53            152.5      1709.0            0.1444   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "\n",
       "[3 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.8</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.6</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.9</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.8</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.0</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.5</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "breast_data = pd.read_csv(\"../datasets/cancer.csv\")\n",
    "breast_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 32    569\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "#Show me only the columns where there are null values\n",
    "breast_data.isna().sum()[breast_data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38           122.8     1001.0   \n",
       "1         M        20.57         17.77           132.9     1326.0   \n",
       "2         M        19.69         21.25           130.0     1203.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33            184.6   \n",
       "1         0.1812  ...         24.99          23.41            158.8   \n",
       "2         0.2069  ...         23.57          25.53            152.5   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.8</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.6</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.9</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.8</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.0</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.5</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "#I am dropping the 'Unnamed 32' column because it is filled with null values\n",
    "#Also getting rid of the id because I do not see that being useful in any way\n",
    "breast_data.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)\n",
    "#Better\n",
    "breast_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "diagnosis    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "#Show me all data fields that aren't a float\n",
    "breast_data.dtypes[breast_data.dtypes != 'float64']\n",
    "#Seems like only y is a string, which is great and we don't need to do further cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's separate our X and y\n",
    "X = breast_data.drop([\"diagnosis\"], axis=1)\n",
    "y = breast_data['diagnosis']\n",
    "\n",
    "#Let's do a train test split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.75, random_state=42, shuffle=True)"
   ]
  },
  {
   "source": [
    "### I am going to fit KNN to this dataset for a few reasons:\n",
    "- There are enough rows to account for the high dimensionality.\n",
    "- The dataset is not too big and therefore we will not face any efficiency issues.\n",
    "- Kmeans is a good fit for data that is not too noisy. (Breasts come in in lots of shapes and sizes but the tumours in this dataset do not `greatly` vary in size)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Another model to consider fitting: Decision Tree / Random Forest\n",
    "- Because there are lots of metrics, a Decision Tree would be able to ignore any unrelated ones easily.\n",
    "- I feel like since we are looking at a topological features of a bodypart, the Decision Tree could come up with good rules to classify the tumour."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'manhattan', 'minkowski',\n",
       "                                    'chebyshev', 'wminkowski', 'seuclidean',\n",
       "                                    'mahalanobis'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30, ...]})"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "#Let's do knn and optimize parameters with GridSearchCV\n",
    "\n",
    "#Parameters for GridSearchCV\n",
    "params = {'n_neighbors': [x for x in range(1, 50)],\n",
    "          'metric': ['euclidean', 'manhattan', 'minkowski', 'chebyshev', 'wminkowski', 'seuclidean', 'mahalanobis']}\n",
    "\n",
    "#Our instance of KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#GridSearchCV to try combinations of parameters\n",
    "clf = GridSearchCV(knn, params, cv=5)\n",
    "\n",
    "#Fitting to the data\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The best parameters that GSCV has found are: {'metric': 'manhattan', 'n_neighbors': 9}\nThe highest acccuracy achieved with these parameters is: 93.852%\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters that GSCV has found are: {}\".format(clf.best_params_))\n",
    "print(\"The highest acccuracy achieved with these parameters is: {}%\".format(np.round(clf.best_score_ * 100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The acccuracy achieved with my implementation of KNN is: 95.804%\n"
     ]
    }
   ],
   "source": [
    "#I am curious what my version of KNN will do, I will stick to euclidean distance\n",
    "k = KNN(9)\n",
    "#Fitting to the training data\n",
    "k.fit(np.array(train_X), np.array(train_y))\n",
    "#Getting predictions\n",
    "predictions = k.predict(np.array(test_X))\n",
    "#Calculating the accuracy score\n",
    "score = accuracy_score(test_y, predictions)\n",
    "\n",
    "print(\"The acccuracy achieved with my implementation of KNN is: {}%\".format(np.round(score * 100, 3)))"
   ]
  },
  {
   "source": [
    "### Small flex: my algorithm did better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Let's create a confusion matrix:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Here is the confusion matrix:\n[[50  4]\n [ 2 87]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(test_y, predictions, labels=['M', 'B'])\n",
    "print(\"Here is the confusion matrix:\\n\" + str(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A true positive means that the diagnosis was malignent and the tumour was malignent.\n\nThe number of true positives is: 50\nThe number of true negatives is: 87\nThe number of false positives is: 4\nThe number of false negatives is: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"A true positive means that the diagnosis was malignent and the tumour was malignent.\\n\")\n",
    "print(\"The number of true positives is:\", matrix[0][0])\n",
    "print(\"The number of true negatives is:\", matrix[1][1])\n",
    "print(\"The number of false positives is:\", matrix[0][1])\n",
    "print(\"The number of false negatives is:\", matrix[1][0])"
   ]
  },
  {
   "source": [
    "### We can observe that the value for false positives is double the value for false negatives, this can be seen as a good thing as a positive test is twice as likely to be incorrect than a negative test. Meaning that your chances of not having a malignent tumor given that the algorithm predicted you did, are greater than your chances of having a malignent tumor given that the algorithm predicted you didn't. (For this model and data split at least)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Let's generate a classification report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n   Malignent       0.96      0.93      0.94        54\n      Benign       0.96      0.98      0.97        89\n\n    accuracy                           0.96       143\n   macro avg       0.96      0.95      0.96       143\nweighted avg       0.96      0.96      0.96       143\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predictions, labels=[\"M\", \"B\"], target_names=[\"Malignent\", \"Benign\"]))"
   ]
  },
  {
   "source": [
    "### We observe some things:\n",
    "- The precision (percentage of correct predictions) for both Malignent and Benign tumors is 96%.\n",
    "- The recall (% of positive cases caught) for benign tumors is greater than the recall for malignent tumors by around 5%.\n",
    "- The F1 score (% of positive predictions that were correct) for benign tumors is 3% greater than the F1 score for malignent tumors, which supports that we can be more confident of a negative classification than a positive classification.\n",
    "- I hypothesize this being due to the higher support metric (occurences in the dataset) for benign tumors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}